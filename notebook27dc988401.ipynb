{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":72632,"databundleVersionId":8059709,"sourceType":"competition"}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndef Dr_Column(value):\n    if 'Dr.' in value:\n        return True\n    else:\n        return False\n\ndef Adv_Column(value):\n    if 'Adv.' in value:\n        return True\n    else:\n        return False\ndef SC_Column(value):\n    if '(SC)' in value:\n        return True\n    else:\n        return False\n\ndef ST_Column(value):\n    if '(ST)' in value:\n        return True\n    else:\n        return False\ndef Numerical(value):\n    if 'Crore+' in value:\n        return int(value.split()[0])*100000\n    elif 'Lac+' in value:\n        return int(value.split()[0])*1000\n    elif 'Thou+' in value:\n        return int(value.split()[0])*10\n    elif 'Hund+' in value:\n        return int(value.split()[0])*1\n    else:\n        return int(value)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-12T17:55:21.499221Z","iopub.execute_input":"2024-04-12T17:55:21.499933Z","iopub.status.idle":"2024-04-12T17:55:23.031449Z","shell.execute_reply.started":"2024-04-12T17:55:21.499897Z","shell.execute_reply":"2024-04-12T17:55:23.030270Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/who-is-the-real-winner/sample_submission.csv\n/kaggle/input/who-is-the-real-winner/train.csv\n/kaggle/input/who-is-the-real-winner/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\nfrom sklearn.naive_bayes import MultinomialNB\n\ntrain_data_path='/kaggle/input/who-is-the-real-winner/train.csv'\ntest_data_path='/kaggle/input/who-is-the-real-winner/test.csv'\n\n# Read the dataset\ntrain_data = pd.read_csv(train_data_path)\ntest_data= pd.read_csv(test_data_path)\n\ntrain_data['Dr'] = train_data['Candidate'].apply(Dr_Column)\ntrain_data['Adv'] = train_data['Candidate'].apply(Adv_Column)\ntest_data['Dr'] = test_data['Candidate'].apply(Dr_Column)\ntest_data['Adv'] = test_data['Candidate'].apply(Adv_Column)\n\ntrain_data['SC'] = train_data['Constituency ∇'].apply(SC_Column)\ntrain_data['ST'] = train_data['Constituency ∇'].apply(ST_Column)\ntest_data['SC'] = test_data['Constituency ∇'].apply(SC_Column)\ntest_data['ST'] = test_data['Constituency ∇'].apply(ST_Column)\n\ntrain_data['Total Assets'] = train_data['Total Assets'].apply(Numerical)\ntest_data['Total Assets'] = test_data['Total Assets'].apply(Numerical)\ntrain_data['Liabilities'] = train_data['Liabilities'].apply(Numerical)\ntest_data['Liabilities'] = test_data['Liabilities'].apply(Numerical)\n\n# Drop columns that are redundant \ntrain_data=train_data.drop(['Candidate','Constituency ∇'], axis=1)\ntest_data=test_data.drop(['Candidate','Constituency ∇'], axis=1)\n\n#Candidate data has been included in Dr, Adv features\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:55:23.033472Z","iopub.execute_input":"2024-04-12T17:55:23.033936Z","iopub.status.idle":"2024-04-12T17:55:25.369803Z","shell.execute_reply.started":"2024-04-12T17:55:23.033905Z","shell.execute_reply":"2024-04-12T17:55:25.368713Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Convert categorical variables into numerical format\n# label_encoder = LabelEncoder()\n# # X['Party'] = label_encoder.fit_transform(X['Party'])\n# # X['Candidate'] = label_encoder.fit_transform(X['Candidate'])\n\n# # One-hot encode the 'Constituency ∇' column\n# # constituency_encoded = pd.get_dummies(X['Constituency ∇'])\n# # X = pd.concat([X, constituency_encoded], axis=1)\n# # X = X.drop(['Constituency ∇'], axis=1)\n\n# Party_encoded = pd.get_dummies(X['Party'])\n# X = pd.concat([X, Party_encoded], axis=1)\n# X = X.drop(['Party'], axis=1)\n\n# state_encoded = pd.get_dummies(X['state'])\n# X = pd.concat([X, state_encoded], axis=1)\n# X = X.drop(['state'], axis=1)\n\n\n\n# Convert 'Total Assets' and 'Liabilities' columns to numerical format\n# X['Total Assets'] = X['Total Assets'].str.replace(' Crore+', 'e7').str.replace(' Lac+', 'e5').str.replace(' Thou+', 'e3').str.replace(' Hund+', 'e2').astype(float)\n# X['Liabilities'] = X['Liabilities'].str.replace(' Crore+', 'e7').str.replace(' Lac+', 'e5').str.replace(' Thou+', 'e3').str.replace(' Hund+', 'e2').astype(float)\n\n# Split the dataset into training and validation sets\n# X_train, X_val, y_train, y_val = train_test_split(X, y,  random_state=1)\n\n# Initialize the KNN classifier\n\n# max=0\n# # for i in range(1,101):   \n# knn = MultinomialNB(alpha=0.6)\n    \n\n#     # Train the classifier\n# knn.fit(X_train, y_train)\n\n#         # Predict on the validation set\n# y_pred = knn.predict(X_val)\n\n#         # Evaluate the model\n# accuracy = f1_score(y_val, y_pred,average='weighted')\n# #     if(accuracy>max):\n# #         max=accuracy\n# #         print(i)\n# # print(max)\n\n\n# print(accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:55:25.371805Z","iopub.execute_input":"2024-04-12T17:55:25.372690Z","iopub.status.idle":"2024-04-12T17:55:25.380704Z","shell.execute_reply.started":"2024-04-12T17:55:25.372647Z","shell.execute_reply":"2024-04-12T17:55:25.379466Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Preprocessing\nfrom sklearn.preprocessing import KBinsDiscretizer\n# train_data = train_data.copy()\ntest_data = test_data.copy()\n\n# Labelling using discretizer\ndiscretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\ntrain_data['Criminal Case'] = discretizer.fit_transform(train_data[['Criminal Case']])\ntrain_data['Total Assets'] = discretizer.fit_transform(train_data[['Total Assets']])\ntrain_data['Liabilities'] = discretizer.fit_transform(train_data[['Liabilities']])\n\n\ntrain_data = pd.get_dummies(train_data, columns=['Party', 'state'])\n\n\nX = train_data.drop(columns=['Education'])  \ny = train_data['Education']  # Replace 'Your_Label_Column' with the column name of the target variable\n\ntest_data['Total Assets'] = discretizer.fit_transform(test_data[['Total Assets']])\ntest_data['Liabilities'] = discretizer.fit_transform(test_data[['Liabilities']])\ntest_data['Criminal Case'] = discretizer.fit_transform(test_data[['Criminal Case']])\n\n# One-hot encode categorical columns (Party and State)\ntest_data = pd.get_dummies(test_data, columns=['Party', 'state'])\n\n# Split data into features and labels\nXTest = test_data  ","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:55:25.383511Z","iopub.execute_input":"2024-04-12T17:55:25.383905Z","iopub.status.idle":"2024-04-12T17:55:25.448486Z","shell.execute_reply.started":"2024-04-12T17:55:25.383876Z","shell.execute_reply":"2024-04-12T17:55:25.446808Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold,cross_val_score\nmodel = MultinomialNB(alpha = 0.06, fit_prior = True)       #tuned\ntrain_X , val_X, train_y, val_y = train_test_split(X,y,random_state = 1)\n\nkf1 = KFold(n_splits = 5, shuffle=True, random_state=48)\n\n# Perform cross-validation\nscores = cross_val_score(model, X, y, cv=kf1, scoring='accuracy')\n\n# Calculate mean and standard deviation of accuracy scores\nmean_accuracy = scores.mean()\nstd_accuracy = scores.std()\nprint(scores)\nprint(mean_accuracy)\nprint(std_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:55:25.449999Z","iopub.execute_input":"2024-04-12T17:55:25.450414Z","iopub.status.idle":"2024-04-12T17:55:25.645962Z","shell.execute_reply.started":"2024-04-12T17:55:25.450380Z","shell.execute_reply":"2024-04-12T17:55:25.644353Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[0.25970874 0.25728155 0.22087379 0.20873786 0.26520681]\n0.2423617508799282\n0.022968298556179916\n","output_type":"stream"}]},{"cell_type":"code","source":"# df = pd.DataFrame({'Education':y_pred})\n# df[\"ID\"] = df.index\n# df.set_index(\"ID\")\n# df.to_csv('sample_submission1.csv',encoding = 'utf-8',index = False)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:55:25.654323Z","iopub.execute_input":"2024-04-12T17:55:25.658717Z","iopub.status.idle":"2024-04-12T17:55:25.667943Z","shell.execute_reply.started":"2024-04-12T17:55:25.658637Z","shell.execute_reply":"2024-04-12T17:55:25.666341Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y)\n\n# Step 3: Model Evaluation\ny_predicted = model.predict(XTest)\nfinal_dataframe = pd.DataFrame(y_predicted, columns=[\"Education\"])\n\nfinal_dataframe.to_csv('Multi_NB.csv', index_label='ID')","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:55:25.675127Z","iopub.execute_input":"2024-04-12T17:55:25.676259Z","iopub.status.idle":"2024-04-12T17:55:25.737540Z","shell.execute_reply.started":"2024-04-12T17:55:25.676182Z","shell.execute_reply":"2024-04-12T17:55:25.735843Z"},"trusted":true},"execution_count":7,"outputs":[]}]}